summarise(Score = sum(Score*population)/sum(population))
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
View(happiness_suicide)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
# Your code he
library(PASWR)
# Your code he
data(PASWR)
# Your code he
# data(PASWR)
PASWR
# Your code he
library(PASWR)
# Your code he
library(PASWR)
dim(titanic3)
str(titanic3)
colSums(is.na(titanic3))
colSums(is.na(titanic3))/nrow(titanic3)
colSums(is.na(titanic3))/nrow(titanic3) *100
colSums(is.na(titanic3))/nrow(titanic3) *100
# Your code here
rowSums(is.na(titanic3))/nrow(titanic3)*100
# Your code here
rowSums(is.na(titanic3))
# colSums(is.na(titanic3))/nrow(titanic3) *100
# colSums(is.na(titanic3))/nrow(titanic3) *100
str(titanic3)
# Your code here
rowSums(is.na(titanic3))>0
# Your code here
sum(rowSums(is.na(titanic3))>0)
# Your code here
sum(rowSums(is.na(titanic3))>0)/nrow(titanic3)
# Your code here
sum(rowSums(is.na(titanic3)))
# Your code here
sum(rowSums(is.na(titanic3))) / (nrow(titanic3)*ncol(titanic3))
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
mean(is.na(titanic3)) * 100
# Your code here
sum(is.na(titanic3)) / (nrow(titanic3)*ncol(titanic3))
# Your code here
sum(is.na(titanic3)) / (nrow(titanic3)*ncol(titanic3)) *100
# Your code here
library(VIM)
aggr(titanic3)
md.pattern(titanic3)
library(mice)
md.pattern(titanic3)
hist(titanic3$age)
# Your code here
table(titanic3$survived, is.na(titanic3$body))
hist(titanic3$age)
# Your code here
table(titanic3$survived, is.na(titanic3$body))
hist(titanic3$age)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(PASWR)
dim(titanic3)
str(titanic3)
summary(titanic3)
# Or using md.pattern() in mice to bulid a data frame or a matrix containing the incomplete data.
# Method 1: Sum of NAs / Total
colSums(is.na(titanic3)) * 100 / nrow(titanic3)
# Method 2: Mean
colMeans(is.na(titanic3)) * 100
# The age variable contains 263 missing values, about 20.09% of this variable.
# The fare variable contains 1 missing value, about 0.08% of this variable.
# The body variable contains 1,188 missing values, about 90.76% of this variable.
sum(!complete.cases(titanic3))
# There are 1,190 observations that contain at least one missing value
mean(!complete.cases(titanic3)) * 100
# about 90.91% of observations in the dataset.
sum(is.na(titanic3))
mean(is.na(titanic3)) * 100
# There are 1,452 missing cells in the entire dataset,
# about 7.92% of all cells in the dataset.
library(VIM)
aggr(titanic3)
library(mice)
md.pattern(titanic3)
# About the graph:
# left: barplot of the proportions of missing values in each variable
# right: all exisiting combinations of missing(red) and non-missing(blue) values in the observations.
# The frequencies of the combinations are visualized by small horizontal bars.
# https://cran.r-project.org/web/packages/VIMGUI/vignettes/VIM-EU-SILC.pdf
#There are four different missingness combinations:
#-Missing just the body variable.
#-Missing just the age variable.
#-Missing just the fare variable.
#-Missing both the age and body variables.
table(titanic3$survived, is.na(titanic3$body))
hist(titanic3$age)
# Your code here
hist(titanic3$age)
age_meanimpute = Hmisc::impute(titanic$age, mean)
library(Hmisc)
age_meanimpute = Hmisc::impute(titanic$age, mean)
age_meanimpute = Hmisc::impute(titanic3$age, mean)
age_meanimpute
hist(age_meanimpute)
# Your code here
hist(titanic3$age)
library(Hmisc)
age_meanimpute = Hmisc::impute(titanic3$age, mean)
hist(age_meanimpute)
# Your code here
age_randomimpute = Hmisc::impute(titanic3$age, random)
# Your code here
age_randomimpute = Hmisc::impute(titanic3$age, 'random')
?Hmisc::impute
hist(age_randomimpute)
hist(titanic3$age)
# Your code here
age_randomimpute = Hmisc::impute(titanic3$age, 'random')
hist(age_randomimpute)
hist(titanic3$age)
# Your code here
set.seed(0)
fare.randomimpute = Hmisc::impute(titanic3$fare, "random")
summary(fare.randomimpute)
# Your code here
scatter(fare.randomimpute, age_randomimpute, color=titanic3$pclass)
# Your code here
plot(fare.randomimpute, age_randomimpute, color=titanic3$pclass)
# Your code here
plot(fare.randomimpute, age_randomimpute, col=titanic3$pclass)
col.vec = NULL
col.vec[titanic3$pclass == "1st"] = "red"
col.vec[titanic3$pclass == "2nd"] = "blue"
col.vec[titanic3$pclass == "3rd"] = "green"
plot(age.randomimpute, fare.randomimpute, col = col.vec)
set.seed(0)
fare.randomimpute = Hmisc::impute(titanic3$fare, "random")
summary(fare.randomimpute) #The one value was imputed to be $69.55
col.vec = NULL
col.vec[titanic3$pclass == "1st"] = "red"
col.vec[titanic3$pclass == "2nd"] = "blue"
col.vec[titanic3$pclass == "3rd"] = "green"
plot(age.randomimpute, fare.randomimpute, col = col.vec)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(PASWR)
dim(titanic3)
str(titanic3)
summary(titanic3)
# Or using md.pattern() in mice to bulid a data frame or a matrix containing the incomplete data.
# Method 1: Sum of NAs / Total
colSums(is.na(titanic3)) * 100 / nrow(titanic3)
# Method 2: Mean
colMeans(is.na(titanic3)) * 100
# The age variable contains 263 missing values, about 20.09% of this variable.
# The fare variable contains 1 missing value, about 0.08% of this variable.
# The body variable contains 1,188 missing values, about 90.76% of this variable.
sum(!complete.cases(titanic3))
# There are 1,190 observations that contain at least one missing value
mean(!complete.cases(titanic3)) * 100
# about 90.91% of observations in the dataset.
sum(is.na(titanic3))
mean(is.na(titanic3)) * 100
# There are 1,452 missing cells in the entire dataset,
# about 7.92% of all cells in the dataset.
library(VIM)
aggr(titanic3)
library(mice)
md.pattern(titanic3)
# About the graph:
# left: barplot of the proportions of missing values in each variable
# right: all exisiting combinations of missing(red) and non-missing(blue) values in the observations.
# The frequencies of the combinations are visualized by small horizontal bars.
# https://cran.r-project.org/web/packages/VIMGUI/vignettes/VIM-EU-SILC.pdf
#There are four different missingness combinations:
#-Missing just the body variable.
#-Missing just the age variable.
#-Missing just the fare variable.
#-Missing both the age and body variables.
table(titanic3$survived, is.na(titanic3$body))
hist(titanic3$age)
#-MCAR: We are only missing one fare observation. It could be the case that this
#       one value is missing because of human error or a simple mistake in data
#       entry.
#-MAR: There is a lot of missingness in the body identification number variable.
#      We notice that there is a relationship between the survived variable and
#      the body variable. It appears as though observations only received a body
#      id if the individual did not survive.
#-MNAR: (Supposition) Elder voyagers might have perished more easily because of
#       their lower mobility. As a result, their ages were not captured as
#       easily by the researchers. The missing values of age depend on the value
#       of age itself.
# 6 Impute using mean value imputation for the age variable.
# 7 Impute using simple random imputation for the age variable.
library(Hmisc)
set.seed(0)
age.meanimpute = Hmisc::impute(titanic3$age, mean)
age.randomimpute = Hmisc::impute(titanic3$age, "random")
plot(density(age.meanimpute), col = "red",
main = "Imputation Methods for Age")
lines(density(age.randomimpute), col = "green")
lines(density(titanic3$age, na.rm = TRUE), col = "blue")
legend("topright", c("Original", "Mean Imputed", "Random Imputed"),
col = c("blue", "red", "green"), lwd = 1)
#Mean Value Imputation: The mean value inputation tends to skew the distribution
#heavily towards the average value of the original dataset. This makes a local
#mode right at the mean, and can make our data appear numerically more centralized
#than it actually is in reality.
#Simple Random Imputation: The resulting distribution is quite similar to the
#original. While structure is retained, if data are MNAR than the resulting imputed
#data will be biased towards values that actually do exist within our dataset.
set.seed(0)
fare.randomimpute = Hmisc::impute(titanic3$fare, "random")
summary(fare.randomimpute) #The one value was imputed to be $69.55
col.vec = NULL
col.vec[titanic3$pclass == "1st"] = "red"
col.vec[titanic3$pclass == "2nd"] = "blue"
col.vec[titanic3$pclass == "3rd"] = "green"
plot(age.randomimpute, fare.randomimpute, col = col.vec)
legend("topleft", c("1st", "2nd", "3rd"),
pch = 1, col = c("red", "blue", "green"))
#Higher fares seem to be associated with 1st class tickets. The older a passenger
#is, the more likely they seem to have an upper-class ticket.
# Your code here
plot( age_randomimpute,fare.randomimpute, col=titanic3$pclass)
plot(age.randomimpute, fare.randomimpute, col = col.vec)
legend("topleft", c("1st", "2nd", "3rd"),
pch = 1, col = c("red", "blue", "green"))
new.people = data.frame(age = c(50, 10), fare = c(400, 100), pclass = NA)
points(new.people, pch = 16)
## use ggplot2
imputed.titanic= as.data.frame(cbind(age.randomimpute,fare.randomimpute,pclass=titanic3$pclass))
ggplot(imputed.titanic,aes(age.randomimpute, fare.randomimpute,colour=as.factor(pclass))) +
geom_point() +
annotate(x=50,y=400,geom = "point",color=I("black"))+annotate(x=10,y=100,geom = "point",color=I("black"))
titanic.imputed = data.frame(age = age.randomimpute,
fare = fare.randomimpute,
pclass = titanic3$pclass)
titanic.1NN = kNN(rbind(titanic.imputed, new.people), k = 1)
#Using 1-NN, both passengers were classified into 1st class.
k <- as.integer(sqrt(nrow(titanic.imputed)))
titanic.36NN = kNN(rbind(titanic.imputed, new.people), k = k)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN
titanic.36NN[pclass_imp==TRUE]
titanic.36NN[titanic36.NN$pclass_imp==TRUE]
titanic.36NN[titanic.36NN$pclass_imp==TRUE]
titanic.36NN
kNN(rbind(titanic.imputed, new.people), k = k)
titanic.36NN = kNN(rbind(titanic.imputed, new.people), k = k)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
summary(titanic.)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
summary(titanic.36NN)
k <- as.integer(sqrt(nrow(titanic.imputed)))
titanic.36NN = kNN(rbind(titanic.imputed, new.people), k = k)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
summary(titanic.36NN)
titanic.imputed = data.frame(age = age.randomimpute,
fare = fare.randomimpute,
pclass = titanic3$pclass)
titanic.1NN = kNN(rbind(titanic.imputed, new.people), k = 1)
#Using 1-NN, both passengers were classified into 1st class.
k <- as.integer(sqrt(nrow(titanic.imputed)))
titanic.36NN = kNN(rbind(titanic.imputed, new.people), k = k)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
summary(titanic.36NN)
summart(titanic.1NN)
summary(titanic.1NN)
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN[is.imputed(titanic.36NN)]
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN[is.imputed(titanic.36NN)]
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN[is.imputed(titanic.36NN),]
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN[is.imputed(titanic.36NN)]
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(PASWR)
dim(titanic3)
str(titanic3)
summary(titanic3)
# Or using md.pattern() in mice to bulid a data frame or a matrix containing the incomplete data.
# Method 1: Sum of NAs / Total
colSums(is.na(titanic3)) * 100 / nrow(titanic3)
# Method 2: Mean
colMeans(is.na(titanic3)) * 100
# The age variable contains 263 missing values, about 20.09% of this variable.
# The fare variable contains 1 missing value, about 0.08% of this variable.
# The body variable contains 1,188 missing values, about 90.76% of this variable.
sum(!complete.cases(titanic3))
# There are 1,190 observations that contain at least one missing value
mean(!complete.cases(titanic3)) * 100
# about 90.91% of observations in the dataset.
sum(is.na(titanic3))
mean(is.na(titanic3)) * 100
# There are 1,452 missing cells in the entire dataset,
# about 7.92% of all cells in the dataset.
library(VIM)
aggr(titanic3)
library(mice)
md.pattern(titanic3)
# About the graph:
# left: barplot of the proportions of missing values in each variable
# right: all exisiting combinations of missing(red) and non-missing(blue) values in the observations.
# The frequencies of the combinations are visualized by small horizontal bars.
# https://cran.r-project.org/web/packages/VIMGUI/vignettes/VIM-EU-SILC.pdf
#There are four different missingness combinations:
#-Missing just the body variable.
#-Missing just the age variable.
#-Missing just the fare variable.
#-Missing both the age and body variables.
table(titanic3$survived, is.na(titanic3$body))
hist(titanic3$age)
#-MCAR: We are only missing one fare observation. It could be the case that this
#       one value is missing because of human error or a simple mistake in data
#       entry.
#-MAR: There is a lot of missingness in the body identification number variable.
#      We notice that there is a relationship between the survived variable and
#      the body variable. It appears as though observations only received a body
#      id if the individual did not survive.
#-MNAR: (Supposition) Elder voyagers might have perished more easily because of
#       their lower mobility. As a result, their ages were not captured as
#       easily by the researchers. The missing values of age depend on the value
#       of age itself.
# 6 Impute using mean value imputation for the age variable.
# 7 Impute using simple random imputation for the age variable.
library(Hmisc)
set.seed(0)
age.meanimpute = Hmisc::impute(titanic3$age, mean)
age.randomimpute = Hmisc::impute(titanic3$age, "random")
plot(density(age.meanimpute), col = "red",
main = "Imputation Methods for Age")
lines(density(age.randomimpute), col = "green")
lines(density(titanic3$age, na.rm = TRUE), col = "blue")
legend("topright", c("Original", "Mean Imputed", "Random Imputed"),
col = c("blue", "red", "green"), lwd = 1)
#Mean Value Imputation: The mean value inputation tends to skew the distribution
#heavily towards the average value of the original dataset. This makes a local
#mode right at the mean, and can make our data appear numerically more centralized
#than it actually is in reality.
#Simple Random Imputation: The resulting distribution is quite similar to the
#original. While structure is retained, if data are MNAR than the resulting imputed
#data will be biased towards values that actually do exist within our dataset.
set.seed(0)
fare.randomimpute = Hmisc::impute(titanic3$fare, "random")
summary(fare.randomimpute) #The one value was imputed to be $69.55
col.vec = NULL
col.vec[titanic3$pclass == "1st"] = "red"
col.vec[titanic3$pclass == "2nd"] = "blue"
col.vec[titanic3$pclass == "3rd"] = "green"
plot(age.randomimpute, fare.randomimpute, col = col.vec)
legend("topleft", c("1st", "2nd", "3rd"),
pch = 1, col = c("red", "blue", "green"))
#Higher fares seem to be associated with 1st class tickets. The older a passenger
#is, the more likely they seem to have an upper-class ticket.
plot(age.randomimpute, fare.randomimpute, col = col.vec)
legend("topleft", c("1st", "2nd", "3rd"),
pch = 1, col = c("red", "blue", "green"))
new.people = data.frame(age = c(50, 10), fare = c(400, 100), pclass = NA)
points(new.people, pch = 16)
## use ggplot2
imputed.titanic= as.data.frame(cbind(age.randomimpute,fare.randomimpute,pclass=titanic3$pclass))
ggplot(imputed.titanic,aes(age.randomimpute, fare.randomimpute,colour=as.factor(pclass))) +
geom_point() +
annotate(x=50,y=400,geom = "point",color=I("black"))+annotate(x=10,y=100,geom = "point",color=I("black"))
titanic.imputed = data.frame(age = age.randomimpute,
fare = fare.randomimpute,
pclass = titanic3$pclass)
titanic.1NN = kNN(rbind(titanic.imputed, new.people), k = 1)
summary(titanic.1NN)
#Using 1-NN, both passengers were classified into 1st class.
#Using 36-NN, the first passenger remained in 1st class because the neighborhood
#nearby contains all 1st class passengers. On the other hand, the other passenger
#is now classified into 3rd class because most of his neighbors are of 3rd class,
#even though his nearest neighbor is in 1st class.
titanic.36NN[is.imputed(titanic.36NN)]
titanic.36NN = kNN(rbind(titanic.imputed, new.people), k = k)
titanic.notimputed = cbind(titanic3[, -c(3, 8:14)], fare = fare.randomimpute)
titanic.notimputed
complete.cases(titanic.notimputed)
complete = titanic.notimputed[complete.cases(titanic.notimputed),]
missing = titanic.notimputed[!complete.cases(titanic.notimputed), -4]
library(kknn)
library(kknn)
?kknn
plot(density(titanic.1nnmanhattan$fitted.values), col = "red",
main = "Minkowski Imputation for Age\n1 Nearest Neighbor")
library(kknn)
titanic.1nnmanhattan = kknn(age ~ ., complete, missing, k = 1, distance = 1)
titanic.1nneuclidean = kknn(age ~ ., complete, missing, k = 1, distance = 2)
titanic.1nnminkowski10 = kknn(age ~ ., complete, missing, k = 1, distance = 10)
?kknn
plot(density(titanic.1nnmanhattan$fitted.values), col = "red",
main = "Minkowski Imputation for Age\n1 Nearest Neighbor")
lines(density(titanic.1nneuclidean$fitted.values), col = "green")
lines(density(titanic.1nnminkowski10$fitted.values), col = "blue")
lines(density(titanic3$age, na.rm = TRUE), col = "purple", lty = 2)
legend("topright", c("Manhattan", "Euclidean", "p = 10", "Original"),
col = c("red", "green", "blue", "purple"), lwd = 1, lty = c(1, 1, 1, 2))
#The different distance measures are each generally matching the age distribution,
#but each are pulling out different local modes because of calculation differences.
plot(density(titanic.1nnmanhattan$fitted.values), col = "red",
main = "Minkowski Imputation for Age\n1 Nearest Neighbor")
lines(density(titanic.1nneuclidean$fitted.values), col = "green")
lines(density(titanic.1nnminkowski10$fitted.values), col = "blue")
lines(density(titanic3$age, na.rm = TRUE), col = "purple", lty = 2)
legend("topright", c("Manhattan", "Euclidean", "p = 10", "Original"),
col = c("red", "green", "blue", "purple"), lwd = 1, lty = c(1, 1, 1, 2))
#The different distance measures are each generally matching the age distribution,
#but each are pulling out different local modes because of calculation differences.
titanic.1nnmanhattan
str(titanic.1nnmanhattan)
titanic.36nnmanhattan = kknn(age ~ ., complete, missing, k = 36, distance = 1)
titanic.36nneuclidean = kknn(age ~ ., complete, missing, k = 36, distance = 2)
titanic.36nnminkowski10 = kknn(age ~ ., complete, missing, k = 36, distance = 10)
plot(density(titanic.36nnmanhattan$fitted.values), col = "red",
main = "Minkowski Imputation for Age\n36 Nearest Neighbors")
lines(density(titanic.36nneuclidean$fitted.values), col = "green")
lines(density(titanic.36nnminkowski10$fitted.values), col = "blue")
lines(density(titanic3$age, na.rm = TRUE), col = "purple", lty = 2)
legend("topright", c("Manhattan", "Euclidean", "p = 10", "Original"),
col = c("red", "green", "blue", "purple"), lwd = 1, lty = c(1, 1, 1, 2))
#As we increase the number of considered neighbors, we see that we tend to
#smooth over local modes and highlight the global aspects of the distribution. As
#a result, the various distance measures tend to appear much similar than they
#did when we only used one neighbor.
# about 90.91% of observations in the dataset.
?mean
runApp()
runApp()
runApp()
runApp()
runApp()
runApp('~/Downloads/happiness_dashboard-master')
